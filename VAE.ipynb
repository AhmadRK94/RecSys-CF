{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40b43cb2",
   "metadata": {},
   "source": [
    "## Variational AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe8482",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6833953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from scipy import sparse\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader \n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce541e58",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9644a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv('df_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f42fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = load_npz('R_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aea946ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users,n_movies = R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3fa2c6",
   "metadata": {},
   "source": [
    "### Prepare data for PyTorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c106ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self,utility_matrix):\n",
    "        self.utility  = utility_matrix\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.utility.shape[0]\n",
    "    def __getitem__(self,idx):\n",
    "        \n",
    "        user_vector = self.utility[[idx],:].toarray()[0]\n",
    "        user_vector = torch.tensor(user_vector,dtype=torch.float32)\n",
    "        \n",
    "        return user_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f142c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieDataset(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5912829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e67cec1",
   "metadata": {},
   "source": [
    "### Constructing accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b0b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_idxs=[]\n",
    "minus_one_idxs=[]\n",
    "hold_out=[]\n",
    "hold_out_minus=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60d55237",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_users):\n",
    "    one_idxs.append(np.where(R[[i],:].toarray()[0] == 1)[0])\n",
    "    minus_one_idxs.append(np.where(R[[i],:].toarray()[0] == -1)[0])\n",
    "    hold_out.append(df_val.query(f\"userId=={i} & rating==1\").movieId.values)\n",
    "    hold_out_minus.append(df_val.query(f\"userId=={i} & rating==-1\").movieId.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08c3e026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_func(model,k=10):\n",
    "    accuracy = []\n",
    "    for i in range(n_users):\n",
    "        output,_,_,_  = model(torch.unsqueeze(train_dataset[i].to(torch.float32).to(device),dim=0))\n",
    "        output = output.to('cpu').detach().numpy()[0]\n",
    "        np.put(output,one_idxs[i],-np.inf)\n",
    "        np.put(output,minus_one_idxs[i],-np.inf)\n",
    "        c = len(np.intersect1d(np.argsort(output)[::-1][:k],hold_out[i]))\n",
    "        nc = len(np.intersect1d(np.argsort(output)[::-1][:k],hold_out_minus[i]))\n",
    "#         acc = np.max([0,(c-nc)/(np.min([k,len(hold_out[i])+1]))]) ## Recal@K\n",
    "        acc = np.max([0,(c-nc)/k]) ## HR@K\n",
    "        accuracy.append(acc)\n",
    "    return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1ed06",
   "metadata": {},
   "source": [
    "### VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fae31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim,dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim,hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim,latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim,latent_dim)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.normalize(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        h1 = self.activation(self.fc1(x))\n",
    "        mu = self.fc_mu(h1)\n",
    "        logvar = self.fc_logvar(h1)\n",
    "        \n",
    "        return mu,logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0b9aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim,hidden_dim)\n",
    "        self.fc_out = nn.Linear(hidden_dim,input_dim)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self,z):\n",
    "        \n",
    "        \n",
    "        h1 = self.activation(self.fc1(self.dropout(z)))\n",
    "        x_rec = self.fc_out(h1)\n",
    "        \n",
    "        return x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d19b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim, latent_dim)\n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5*logvar)\n",
    "            epsilon = torch.randn_like(std)\n",
    "            z = mu + epsilon * std\n",
    "            return z\n",
    "        else:\n",
    "            z = mu\n",
    "            return z\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu,logvar)\n",
    "        x_rec = self.decoder(z)\n",
    "        \n",
    "        return x_rec,z, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43f8262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ELBOLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def kl_divergence(self, z, mu, logvar):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        std = torch.exp(logvar / 2)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "\n",
    "    def forward(self,x_rec,x,z,mu,logvar,beta=0.2):\n",
    "#         construction_error = -torch.mean(torch.sum(F.log_softmax(x_rec,dim=1) * x, dim=-1)) ## multinomial loss \n",
    "        construction_error = F.mse_loss(x_rec,x) ### mean square error loss\n",
    "        kl = self.kl_divergence(z,mu,logvar) ## kl divergence\n",
    "#         kl_divergence = torch.mean(-0.5*torch.sum(1 + logvar - mu.pow(2)-logvar.exp(),dim=1),dim=0) ## kl divergence\n",
    "        return construction_error + (beta*kl).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d467dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67b703f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = ELBOLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57607ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vae = VAE(n_movies,256,128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "031f87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_vae.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a05c6",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40ff5aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1,train loss: 0.1507, val accuracy: 0.0168\n",
      "Epoch 2,train loss: 0.1182, val accuracy: 0.0722\n",
      "Epoch 3,train loss: 0.0971, val accuracy: 0.1026\n",
      "Epoch 4,train loss: 0.0796, val accuracy: 0.1180\n",
      "Epoch 5,train loss: 0.0665, val accuracy: 0.1259\n",
      "Epoch 6,train loss: 0.0584, val accuracy: 0.1341\n",
      "Epoch 7,train loss: 0.0522, val accuracy: 0.1427\n",
      "Epoch 8,train loss: 0.0484, val accuracy: 0.1484\n",
      "Epoch 9,train loss: 0.0451, val accuracy: 0.1544\n",
      "Epoch 10,train loss: 0.0434, val accuracy: 0.1595\n",
      "Epoch 11,train loss: 0.0410, val accuracy: 0.1631\n",
      "Epoch 12,train loss: 0.0399, val accuracy: 0.1639\n",
      "Epoch 13,train loss: 0.0392, val accuracy: 0.1654\n",
      "Epoch 14,train loss: 0.0385, val accuracy: 0.1666\n",
      "Epoch 15,train loss: 0.0380, val accuracy: 0.1669\n",
      "Epoch 16,train loss: 0.0382, val accuracy: 0.1672\n",
      "Epoch 17,train loss: 0.0374, val accuracy: 0.1673\n",
      "Epoch 18,train loss: 0.0375, val accuracy: 0.1672\n",
      "Epoch 19,train loss: 0.0361, val accuracy: 0.1676\n",
      "Epoch 20,train loss: 0.0372, val accuracy: 0.1676\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_vae.train()\n",
    "    train_losses = []\n",
    "    for i,x in enumerate(train_loader):\n",
    "        x = x.to(device).to(torch.float32)\n",
    "        x_rec,z,mu,logvar = model_vae(x)\n",
    "        \n",
    "        cost = loss_func(x_rec,x,z,mu,logvar)\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(cost.item())\n",
    "    \n",
    "    model_vae.eval()\n",
    "    acc = accuracy_func(model_vae,10)\n",
    "    \n",
    "\n",
    "    print(f\"Epoch {epoch + 1},train loss: {torch.tensor(train_losses).mean():.4f}, val accuracy: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
